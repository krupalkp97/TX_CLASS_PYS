{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing fundamental lib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlcontext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data using sqlcontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|               query|      labels|\n",
      "+--------------------+------------+\n",
      "|can i see gastroe...|Appointment |\n",
      "|Now I am at Qatar...|Appointment |\n",
      "|We need dr. g. ve...|Appointment |\n",
      "|i want to book ap...|Appointment |\n",
      "|book appointment ...|Appointment |\n",
      "+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = sqlcontext.read.format('com.databricks.spark.csv').options(header='true',inferschema='true').load('/home/DEADPOOL/Downloads/kauvery.csv')\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- query: string (nullable = true)\n",
      " |-- labels: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading lib for processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer,StopWordsRemover,CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular expressin tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"query\", outputCol=\"words\", pattern=\"\\\\W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init pipeline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+--------------------+--------------------+-----+\n",
      "|               query|      labels|               words|            filtered|            features|label|\n",
      "+--------------------+------------+--------------------+--------------------+--------------------+-----+\n",
      "|can i see gastroe...|Appointment |[can, i, see, gas...|[can, i, see, gas...|(229,[1,5,10,16,3...|  7.0|\n",
      "|Now I am at Qatar...|Appointment |[now, i, am, at, ...|[now, i, am, at, ...|(229,[0,1,3,9,16,...|  7.0|\n",
      "|We need dr. g. ve...|Appointment |[we, need, dr, g,...|[we, need, dr, g,...|(229,[4,31,33,61,...|  7.0|\n",
      "|i want to book ap...|Appointment |[i, want, to, boo...|[i, want, to, boo...|(229,[1,3,10,19,3...|  7.0|\n",
      "|book appointment ...|Appointment |[book, appointmen...|[book, appointmen...|(229,[10,31,57,79...|  7.0|\n",
      "+--------------------+------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "label_stringIdx = StringIndexer(inputCol = \"labels\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)\n",
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 1193\n",
      "Test Dataset Count: 520\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|               query|              labels|               words|            filtered|            features|label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "| Hi, this is vija...|  Disease Inquiries |[hi, this, is, vi...|[hi, this, is, vi...|(229,[6,8,10,58,8...| 35.0|\n",
      "|         I hate you |   system_agent_bad |      [i, hate, you]|      [i, hate, you]|(229,[0,1],[1.0,1...| 15.0|\n",
      "|     bye good night |system_greetings_...|  [bye, good, night]|  [bye, good, night]|(229,[7,56,88],[1...| 22.0|\n",
      "|                BRB |system_user_will_...|               [brb]|               [brb]|         (229,[],[])| 75.0|\n",
      "|Can I make a rese...|        Appointment |[can, i, make, a,...|[can, i, make, a,...|(229,[1,10,15,16,...|  7.0|\n",
      "|Can i have Dr.Rag...|        Appointment |[can, i, have, dr...|[can, i, have, dr...|(229,[1,4,16,31,3...|  7.0|\n",
      "|Consultation with...|        Appointment |[consultation, wi...|[consultation, wi...|(229,[30,61],[1.0...|  7.0|\n",
      "|Contact Information |    General Contact |[contact, informa...|[contact, informa...|(229,[55,182],[1....| 58.0|\n",
      "|Courses in your c...|    College Queries |[courses, in, you...|[courses, in, you...|(229,[9,26,222],[...| 83.0|\n",
      "|Hai Sir I am Nand...|             Career |[hai, sir, i, am,...|[hai, sir, i, am,...|(229,[1,19,26,35,...| 40.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using Count Vector Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------------+------------------------------+-----+----------+\n",
      "|                query|                labels|                   probability|label|prediction|\n",
      "+---------------------+----------------------+------------------------------+-----+----------+\n",
      "|that was pretty good |system_appraisal_good |[0.3275237132516771,0.03274...|  0.0|       0.0|\n",
      "|  that's much better |system_appraisal_good |[0.2997635435289294,0.03933...|  0.0|       0.0|\n",
      "|  that was very good |system_appraisal_good |[0.27629257922695577,0.0359...|  0.0|       0.0|\n",
      "|  that's really nice |system_appraisal_good |[0.27373215400968837,0.0425...|  0.0|       0.0|\n",
      "|      that's amazing |system_appraisal_good |[0.2688603734722277,0.04522...|  0.0|       0.0|\n",
      "|    that's very good |system_appraisal_good |[0.26509744592293744,0.0440...|  0.0|       0.0|\n",
      "|   that is wonderful |system_appraisal_good |[0.25510376779754373,0.0448...|  0.0|       0.0|\n",
      "|    that was awesome |system_appraisal_good |[0.21939639788122045,0.0391...|  0.0|       0.0|\n",
      "|      that's awesome |system_appraisal_good |[0.20788170674194872,0.0473...|  0.0|       0.0|\n",
      "|  that's a good idea |system_appraisal_good |[0.19770248996462148,0.0483...|  0.0|       0.0|\n",
      "+---------------------+----------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"query\",\"labels\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5196933448904881"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------------+------------------------------+-----+----------+\n",
      "|                query|                labels|                   probability|label|prediction|\n",
      "+---------------------+----------------------+------------------------------+-----+----------+\n",
      "|that was pretty good |system_appraisal_good |[0.31434005167237633,0.0329...|  0.0|       0.0|\n",
      "|  that's much better |system_appraisal_good |[0.3006612596363839,0.03913...|  0.0|       0.0|\n",
      "|  that's really nice |system_appraisal_good |[0.26979213170913524,0.0425...|  0.0|       0.0|\n",
      "|    that's very good |system_appraisal_good |[0.2665079330845293,0.04380...|  0.0|       0.0|\n",
      "|  that was very good |system_appraisal_good |[0.2655567916586436,0.03613...|  0.0|       0.0|\n",
      "|   that is wonderful |system_appraisal_good |[0.2551214410323665,0.04446...|  0.0|       0.0|\n",
      "|      that's amazing |system_appraisal_good |[0.24968306394704187,0.0460...|  0.0|       0.0|\n",
      "|    that was awesome |system_appraisal_good |[0.2094790994983941,0.03908...|  0.0|       0.0|\n",
      "|      that's awesome |system_appraisal_good |[0.20876572766622992,0.0470...|  0.0|       0.0|\n",
      "|  that's a good idea |system_appraisal_good |[0.198731202268065,0.048085...|  0.0|       0.0|\n",
      "+---------------------+----------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"query\",\"labels\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.512120070862926"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation with hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6157652135213346"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0.8)\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)#\n",
    "#             .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#             .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "cvModel = cv.fit(trainingData)\n",
    "\n",
    "predictions = cvModel.transform(testData)\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------------+------------------------------+-----+----------+\n",
      "|                query|                labels|                   probability|label|prediction|\n",
      "+---------------------+----------------------+------------------------------+-----+----------+\n",
      "|    that's very good |system_appraisal_good |[0.9770296971060535,0.00357...|  0.0|       0.0|\n",
      "|  that's really nice |system_appraisal_good |[0.960007974205793,0.004547...|  0.0|       0.0|\n",
      "|  that was very good |system_appraisal_good |[0.955311984259193,0.001911...|  0.0|       0.0|\n",
      "|      it's very good |system_appraisal_good |[0.9348725920923162,0.00488...|  0.0|       0.0|\n",
      "|      it's very good |system_appraisal_good |[0.9348725920923162,0.00488...|  0.0|       0.0|\n",
      "|that was pretty good |system_appraisal_good |[0.915807342919953,0.004276...|  0.0|       0.0|\n",
      "|  that's a good idea |system_appraisal_good |[0.8930461816264039,0.01142...|  0.0|       0.0|\n",
      "|      that's amazing |system_appraisal_good |[0.8580818006669823,0.03318...|  0.0|       0.0|\n",
      "|      that's awesome |system_appraisal_good |[0.8474255227538084,0.03277...|  0.0|       0.0|\n",
      "|         that's cute |system_appraisal_good |[0.8060519860845473,0.04675...|  0.0|       0.0|\n",
      "+---------------------+----------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"query\",\"labels\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4003601818816952"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------+------------------------------+-----+----------+\n",
      "|                  query|                labels|                   probability|label|prediction|\n",
      "+-----------------------+----------------------+------------------------------+-----+----------+\n",
      "|    that's a good idea |system_appraisal_good |[0.09237279657549714,0.0622...|  0.0|       0.0|\n",
      "|      that's very good |system_appraisal_good |[0.09237279657549714,0.0622...|  0.0|       0.0|\n",
      "|    oh that's not good | system_appraisal_bad |[0.09154682958387059,0.0622...|  6.0|       0.0|\n",
      "|       that's not good | system_appraisal_bad |[0.09154682958387059,0.0622...|  6.0|       0.0|\n",
      "|that's not good enough | system_appraisal_bad |[0.09154682958387059,0.0622...|  6.0|       0.0|\n",
      "|        that's awesome |system_appraisal_good |[0.09029608846671203,0.0625...|  0.0|       0.0|\n",
      "|           that's lame | system_appraisal_bad |[0.08983543417847151,0.0630...|  6.0|       0.0|\n",
      "|        that's amazing |system_appraisal_good |[0.08983543417847151,0.0630...|  0.0|       0.0|\n",
      "|     haha that's funny |system_emotions_ha_ha |[0.08983543417847151,0.0630...| 16.0|       0.0|\n",
      "|    that's all goodbye | system_greetings_bye |[0.08983543417847151,0.0630...| 14.0|       0.0|\n",
      "+-----------------------+----------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(trainingData)\n",
    "predictions = rfModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"query\",\"labels\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32805372269693417"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
